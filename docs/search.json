[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About Us",
    "section": "",
    "text": "1 Members\n\n\n\nKen Pu is an associate professor in Computer Science at Ontario Tech University. He has been actively working in the intersection of database systems, text and natural language processing, machine learning and artificial intelligence. He received his PhD in Computer Science from University of Toronto in 2006.\n\n\n\n\n\n\n\nFarees Siddiqui, MSc in Computer Science, 2025-2027\n\n\n\n\n\n\n\nZikun Fu, MSc in Computer Science, 2023-2025.\n\n\n\n\n\n\n\nLevi Willm, BSc in Computer Science\n\n\n\n\n\n\n\nEthan Janovitz, BSc in Computer Science\n\n\n\n\n\n\n\nDatabase & Automated Workflow, 2025 ©"
  },
  {
    "objectID": "publications.html",
    "href": "publications.html",
    "title": "Publications",
    "section": "",
    "text": "A complete list can be found on Google Scholar.\n\n\n\nMa, L., Pu, K., Zhu, Y., & Taylor, W. (2025). Comparing large language models for generating complex queries. Journal of Computer and Communications, 13(2), 236–249.\nFu, Z., Chen, Y., Davoudi, K., & Pu, K. Q. (2025). Database entity recognition with data augmentation and deep learning. IEEE 26th International Conference on Information Reuse and Integration, 1–6.\nMa, L., Pu, K., & Zhu, Y. (2024). Evaluating llms for text-to-sql generation with complex sql workload. arXiv Preprint arXiv:2407.19517.\nMekael Wasti, S., Pu, K. Q., & Neshati, A. (2024). Large language user interfaces: Voice interactive user interfaces powered by LLMs. arXiv e-Prints, arXiv–2402.\nWasti, S. M., Pu, K. Q., & Neshati, A. (2024). Large language user interfaces: Voice interactive user interfaces powered by LLMs. Intelligent Systems Conference, 639–655.\nMa, L., & Pu, K. Q. (2024). Accelerating relational keyword queries with embedded predictive neural networks. 2024 IEEE International Conference on Information Reuse and Integration for Data Science (IRI), 84–89.\nFu, Z., Yang, C., Davoudi, H., & Pu, K. (2024). Transforming text-to-SQL datasets into closed-domain NER benchmark. Ontario DataBase Day–Program, 12.\nNargesian, F., Pu, K., Ghadiri-Bashardoost, B., Zhu, E., & Miller, R. J. (2022). Data lake organization. IEEE Transactions on Knowledge and Data Engineering, 35(1), 237–250.\nPu, K., & Ma, L. (2022). Incremental computation of information gain in temporal relational streams. 2022 IEEE 23rd International Conference on Information Reuse and Integration for Data Science (IRI), 234–235.\nMa, L., & Pu, K. Q. (2022). Neural network accelerated tuple search for relational data. 2022 IEEE 23rd International Conference on Information Reuse and Integration for Data Science (IRI), 81–82.\nOuellette, P., Sciortino, A., Nargesian, F., Bashardoost, B. G., Zhu, E., Pu, K. Q., & Miller, R. J. (2021). RONIN: Data lake exploration. Proceedings of the VLDB Endowment, 14(12).\nNargesian, F., Pu, K. Q., Zhu, E., Ghadiri Bashardoost, B., & Miller, R. J. (2020). Organizing data lakes for navigation. Proceedings of the 2020 ACM SIGMOD International Conference on Management of Data, 1939–1950.\nHelala, M. A., Qureshi, F. Z., & Pu, K. Q. (2020). A stream algebra for performance optimization of large scale computer vision pipelines. IEEE Transactions on Pattern Analysis and Machine Intelligence, 44(2), 905–923.\nPolovina, S., Polovina, R., Kemp, N., & Pu, K. (2020). MOVE: Measuring ontologies in value-seeking environments: CSCW for human adaptation. Companion Publication of the 2020 Conference on Computer Supported Cooperative Work and Social Computing, 475–482.\nMior, M. J., & Pu, K. Q. (2020). Semantic data understanding with character level learning. 2020 IEEE 21st International Conference on Information Reuse and Integration for Data Science (IRI), 253–258.\nStoica, A., Pu, K. Q., & Davoudi, H. (2020). NLP relational queries and its application. 2020 IEEE 21st International Conference on Information Reuse and Integration for Data Science (IRI), 395–398.\nValdron, M., & Pu, K. Q. (2020). Data driven relational constraint programming. 2020 IEEE 21st International Conference on Information Reuse and Integration for Data Science (IRI), 156–163.\nNargesian, F., Zhu, E., Miller, R. J., Pu, K. Q., & Arocena, P. C. (2019). Data lake management: Challenges and opportunities. Proceedings of the VLDB Endowment, 12(12), 1986–1989.\nBeirami, A., Zhu, Y., & Pu, K. (2019). Trusted relational databases with blockchain: Design and optimization. Procedia Computer Science, 155, 137–144.\nStoica, A., Valdron, M., & Pu, K. (2019). Scalable analysis of open data graphs. 2019 IEEE 20th International Conference on Information Reuse and Integration for Data Science (IRI), 334–341.\nNargesian, F., Zhu, E., Pu, K. Q., & Miller, R. J. (2018). Table union search on open data. Proceedings of the VLDB Endowment, 11(7), 813–825.\nMiller, R. J., Nargesian, F., Zhu, E., Christodoulakis, C., Pu, K. Q., & Andritsos, P. (2018). Making open data transparent: Data discovery on open data. IEEE Data Eng. Bull., 41(2), 59–70.\nBeiraimi, A., Pu, K., & Zhu, Y. (2018). Towards optimal snapshot materialization to support large query workload for append-only temporal databases. 2018 IEEE International Congress on Big Data (BigData Congress), 268–271.\nNargesian, F., Pu, K. Q., Bashardoost, B. G., Zhu, E., & Miller, R. J. (2018). Data lake organization. arXiv Preprint arXiv:1812.07024.\nHedrick, A., Zhu, Y., & Pu, K. (2017). Modeling transition and mobility patterns. International Conference on Applied Human Factors and Ergonomics, 528–537.\nZhu, E., Pu, K. Q., Nargesian, F., & Miller, R. J. (2017). Interactive navigation of open data linkages. Proceedings of the VLDB Endowment, 10(12), 1837–1840.\nReina, E., Pu, K. Q., & Qureshi, F. Z. (2017). An index structure for fast range search in hamming space. 2017 14th Conference on Computer and Robot Vision (CRV), 8–15.\nZhu, E., Nargesian, F., Pu, K. Q., & Miller, R. J. (2016). LSH ensemble: Internet-scale domain search. arXiv Preprint arXiv:1603.07410.\nHelala, M. A., Pu, K. Q., & Qureshi, F. Z. (2016). A formal algebra implementation for distributed image and video stream processing. Proceedings of the 10th International Conference on Distributed Smart Camera, 84–91.\nFerron, M., Pu, K. Q., & Szlichta, J. (2016). ARC: A pipeline approach enabling large-scale graph visualization. 2016 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining (ASONAM), 1397–1400.\nHedrick, A., Pu, K. Q., & Zhu, Y. (2016). Hierarchical temporal mobility analysis with semantic labeling. 2016 International Conference on Computational Science and Computational Intelligence (CSCI), 1321–1326.\nHelala, M. A., Qureshi, F. Z., & Pu, K. Q. (2015). Automatic parsing of lane and road boundaries in challenging traffic scenes. Journal of Electronic Imaging, 24(5), 053020–053020.\nYu, Z., Liu, Y., Yu, X., & Pu, K. Q. (2014). Scalable distributed processing of k nearest neighbor queries over moving objects. IEEE Transactions on Knowledge and Data Engineering, 27(5), 1383–1396.\nHelala, M. A., Pu, K. Q., & Qureshi, F. Z. (2014). A stream algebra for computer vision pipelines. Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops, 786–793.\nHelala, M. A., Pu, K. Q., & Qureshi, F. Z. (2014). Towards efficient feedback control in streaming computer vision pipelines. Asian Conference on Computer Vision, 314–329.\nDrake, R., & Pu, K. Q. (2014). Using document space for relational search. Proceedings of the 2014 IEEE 15th International Conference on Information Reuse and Integration (IEEE IRI 2014), 841–844.\nHassanzadeh, O., Pu, K. Q., Yeganeh, S. H., Miller, R. J., Popa, L., Hernández, M. A., & Ho, H. (2013). Discovering linkage points over web data. Proceedings of the VLDB Endowment, 6(6), 445–456.\nHelala, M. A., Pu, K. Q., & Qureshi, F. Z. (2012). Road boundary detection in challenging scenarios. 2012 IEEE Ninth International Conference on Advanced Video and Signal-Based Surveillance, 428–433.\nHedrick, A., & Pu, K. Q. (2012). Authoring relational queries on the mobile devices. Procedia Computer Science, 10, 752–757.\nMalloy, W. E., & Pu, K. Q. (2012). Systems and computer program products to identify related data in a multidimensional database.\nRachevsky, L., & Pu, K. Q. (2011). Selection of features for surname classification. 2011 IEEE International Conference on Information Reuse & Integration, 15–20.\nPu, K. Q., & Cheung, R. (2011). Tag grid: Supporting multidimensional queries of tagged datasets. In Recent trends in information reuse and integration (pp. 331–342). Springer Vienna Vienna.\nPu, K. Q., Hassanzadeh, O., Drake, R., & Miller, R. J. (2010). Online annotation of text streams with structured entities. Proceedings of the 19th ACM International Conference on Information and Knowledge Management, 29–38.\nPu, K. Q., & Cheung, R. (2010). Tag grid: Supporting collaborative and fuzzy multidimensional queries of tagged datasets. 2010 IEEE International Conference on Information Reuse & Integration, 364–367.\nQ Pu, K. (2010). Recent patents on information retrieval using natural language and keyword query. Recent Patents on Computer Science, 3(3), 186–194.\nPu, K. Q. (2009). Keyword query cleaning using hidden markov models. Proceedings of the First International Workshop on Keyword Search on Structured Data, 27–32.\nBourennani, F., Pu, K. Q., & Zhu, Y. (2009). Visual integration tool for heterogeneous data type by unified vectorization. 2009 IEEE International Conference on Information Reuse & Integration, 132–137.\nBourennani, F., Pu, K. Q., & Zhu, Y. (2009). Visualization and integration of databases using self-organizing map. 2009 First International Confernce on Advances in Databases, Knowledge, and Data Applications, 155–160.\nPu, K. Q., & Yu, X. (2009). Frisk: Keyword query cleaning and processing in action. 2009 IEEE 25th International Conference on Data Engineering, 1531–1534.\nZhu, Y., Howard, W., & Pu, K. Q. (2009). Spatial inference using networks of RFID receiver: A bayesian approach. GLOBECOM 2009-2009 IEEE Global Telecommunications Conference, 1–6.\nBourennani, F., Pu, K. Q., & Zhu, Y. (2009). Unified vectorization of numerical and textual data using self-organizing map. International Journal On Advances in Systems and Measurements, 2.\nPu, K. Q. (2009). Analysis of service compatibility. Services and Business Computing Solutions with XML: Applications for Quality, 136.\nPu, K. Q., & Yu, X. (2008). Keyword query cleaning. Proceedings of the VLDB Endowment, 1(1), 909–920.\nZhu, Y., Li, B., & Pu, K. Q. (2008). Dynamic multicast in overlay networks with linear capacity constraints. IEEE Transactions on Parallel and Distributed Systems, 20(7), 925–939.\nMalloy, W. E., & Pu, K. Q. (2008). Methods to identify related data in a multidimensional database.\nZhu, Y., & Pu, K. Q. (2008). Adaptive multicast tree construction for elastic data streams. IEEE GLOBECOM 2008-2008 IEEE Global Telecommunications Conference, 1–5.\nPu, K. Q., & Zhu, Y. (2008). Modeling and synthesis of service composition using tree automata. 2008 IEEE International Conference on Information Reuse and Integration, 46–51.\nPu, K. Q., & Zhu, Y. (2007). Efficient indexing of heterogeneous data streams with automatic performance configurations. 19th International Conference on Scientific and Statistical Database Management (SSDBM 2007), 34–34.\nPu, K. Q. (2007). Service description and analysis from a type theoretic approach. 2007 IEEE 23rd International Conference on Data Engineering Workshop, 379–386.\nPu, K. Q., & Zhu, Y. (2007). Fast archiving and querying of heterogeneous sensor data streams. 2007 Second International Conference on Digital Telecommunications (ICDT’07), 28–28.\nPu, K., Hristidis, V., & Koudas, N. (2006). Syntactic rule based approach toweb service composition. 22nd International Conference on Data Engineering (ICDE’06), 31–31.\nChandel, A., Koudas, N., Pu, K. Q., & Srivastava, D. (2006). Fast identification of relational constraint violations. 2007 IEEE 23rd International Conference on Data Engineering, 776–785.\nPu, Q. K. (2006). On formal methods of multidimensional databases [PhD thesis].\nYu, X., Pu, K. Q., & Koudas, N. (2005). Monitoring k-nearest neighbor queries over moving objects. 21st International Conference on Data Engineering (ICDE’05), 631–642.\nPu, K. Q., & Mendelzon, A. O. (2005). Concise descriptions of subsets of structured sets. ACM Transactions on Database Systems (TODS), 30(1), 211–248.\nPu, K. Q. (2005). Modeling, querying and reasoning about OLAP databases: A functional approach. Proceedings of the 8th ACM International Workshop on Data Warehousing and OLAP, 1–8.\nPu, K. Q., & Mendelzon, A. O. (2005). Typed functional query languages with equational specifications. Proceedings of the 14th ACM International Conference on Information and Knowledge Management, 233–234.\nPu, K. Q. (2004). Functional integration of relational, OLAP and XML data. Proceedings of VLDB Workshop on Information Integration on the Web (IIWeb-2004), 97.\nMendelzon, A. O., & Pu, K. Q. (2003). Concise descriptions of subsets of structured sets. Proceedings of the Twenty-Second ACM SIGMOD-SIGACT-SIGART Symposium on Principles of Database Systems, 123–133.\nPu, K. (2000). Modeling and control of discrete-event systems with hierarchical abstraction. Ma sc [PhD thesis]. Thesis, Dept. of Electl. & Cmptr. Engrg., Univ. of Toronto.\nPu, K. Q. (1998). Theory of discrete wavelet transform and an error analysis of the pyramid algorithm [PhD thesis]. Citeseer.\n\n\n\n\n\n\nReferences\n\nFu, Z., Chen, Y., Davoudi, K., & Pu, K. Q. (2025). Database entity recognition with data augmentation and deep learning. IEEE 26th International Conference on Information Reuse and Integration, 1–6.\n\n\nMa, L., Pu, K., Zhu, Y., & Taylor, W. (2025). Comparing large language models for generating complex queries. Journal of Computer and Communications, 13(2), 236–249.\n\n\nFu, Z., Yang, C., Davoudi, H., & Pu, K. (2024). Transforming text-to-SQL datasets into closed-domain NER benchmark. Ontario DataBase Day–Program, 12.\n\n\nMa, L., & Pu, K. Q. (2024). Accelerating relational keyword queries with embedded predictive neural networks. 2024 IEEE International Conference on Information Reuse and Integration for Data Science (IRI), 84–89.\n\n\nMa, L., Pu, K., & Zhu, Y. (2024). Evaluating llms for text-to-sql generation with complex sql workload. arXiv Preprint arXiv:2407.19517.\n\n\nMekael Wasti, S., Pu, K. Q., & Neshati, A. (2024). Large language user interfaces: Voice interactive user interfaces powered by LLMs. arXiv e-Prints, arXiv–2402.\n\n\nWasti, S. M., Pu, K. Q., & Neshati, A. (2024). Large language user interfaces: Voice interactive user interfaces powered by LLMs. Intelligent Systems Conference, 639–655.\n\n\nMa, L., & Pu, K. Q. (2022). Neural network accelerated tuple search for relational data. 2022 IEEE 23rd International Conference on Information Reuse and Integration for Data Science (IRI), 81–82.\n\n\nNargesian, F., Pu, K., Ghadiri-Bashardoost, B., Zhu, E., & Miller, R. J. (2022). Data lake organization. IEEE Transactions on Knowledge and Data Engineering, 35(1), 237–250.\n\n\nPu, K., & Ma, L. (2022). Incremental computation of information gain in temporal relational streams. 2022 IEEE 23rd International Conference on Information Reuse and Integration for Data Science (IRI), 234–235.\n\n\nOuellette, P., Sciortino, A., Nargesian, F., Bashardoost, B. G., Zhu, E., Pu, K. Q., & Miller, R. J. (2021). RONIN: Data lake exploration. Proceedings of the VLDB Endowment, 14(12).\n\n\nHelala, M. A., Qureshi, F. Z., & Pu, K. Q. (2020). A stream algebra for performance optimization of large scale computer vision pipelines. IEEE Transactions on Pattern Analysis and Machine Intelligence, 44(2), 905–923.\n\n\nMior, M. J., & Pu, K. Q. (2020). Semantic data understanding with character level learning. 2020 IEEE 21st International Conference on Information Reuse and Integration for Data Science (IRI), 253–258.\n\n\nNargesian, F., Pu, K. Q., Zhu, E., Ghadiri Bashardoost, B., & Miller, R. J. (2020). Organizing data lakes for navigation. Proceedings of the 2020 ACM SIGMOD International Conference on Management of Data, 1939–1950.\n\n\nPolovina, S., Polovina, R., Kemp, N., & Pu, K. (2020). MOVE: Measuring ontologies in value-seeking environments: CSCW for human adaptation. Companion Publication of the 2020 Conference on Computer Supported Cooperative Work and Social Computing, 475–482.\n\n\nStoica, A., Pu, K. Q., & Davoudi, H. (2020). NLP relational queries and its application. 2020 IEEE 21st International Conference on Information Reuse and Integration for Data Science (IRI), 395–398.\n\n\nValdron, M., & Pu, K. Q. (2020). Data driven relational constraint programming. 2020 IEEE 21st International Conference on Information Reuse and Integration for Data Science (IRI), 156–163.\n\n\nBeirami, A., Zhu, Y., & Pu, K. (2019). Trusted relational databases with blockchain: Design and optimization. Procedia Computer Science, 155, 137–144.\n\n\nNargesian, F., Zhu, E., Miller, R. J., Pu, K. Q., & Arocena, P. C. (2019). Data lake management: Challenges and opportunities. Proceedings of the VLDB Endowment, 12(12), 1986–1989.\n\n\nStoica, A., Valdron, M., & Pu, K. (2019). Scalable analysis of open data graphs. 2019 IEEE 20th International Conference on Information Reuse and Integration for Data Science (IRI), 334–341.\n\n\nBeiraimi, A., Pu, K., & Zhu, Y. (2018). Towards optimal snapshot materialization to support large query workload for append-only temporal databases. 2018 IEEE International Congress on Big Data (BigData Congress), 268–271.\n\n\nMiller, R. J., Nargesian, F., Zhu, E., Christodoulakis, C., Pu, K. Q., & Andritsos, P. (2018). Making open data transparent: Data discovery on open data. IEEE Data Eng. Bull., 41(2), 59–70.\n\n\nNargesian, F., Pu, K. Q., Bashardoost, B. G., Zhu, E., & Miller, R. J. (2018). Data lake organization. arXiv Preprint arXiv:1812.07024.\n\n\nNargesian, F., Zhu, E., Pu, K. Q., & Miller, R. J. (2018). Table union search on open data. Proceedings of the VLDB Endowment, 11(7), 813–825.\n\n\nHedrick, A., Zhu, Y., & Pu, K. (2017). Modeling transition and mobility patterns. International Conference on Applied Human Factors and Ergonomics, 528–537.\n\n\nReina, E., Pu, K. Q., & Qureshi, F. Z. (2017). An index structure for fast range search in hamming space. 2017 14th Conference on Computer and Robot Vision (CRV), 8–15.\n\n\nZhu, E., Pu, K. Q., Nargesian, F., & Miller, R. J. (2017). Interactive navigation of open data linkages. Proceedings of the VLDB Endowment, 10(12), 1837–1840.\n\n\nFerron, M., Pu, K. Q., & Szlichta, J. (2016). ARC: A pipeline approach enabling large-scale graph visualization. 2016 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining (ASONAM), 1397–1400.\n\n\nHedrick, A., Pu, K. Q., & Zhu, Y. (2016). Hierarchical temporal mobility analysis with semantic labeling. 2016 International Conference on Computational Science and Computational Intelligence (CSCI), 1321–1326.\n\n\nHelala, M. A., Pu, K. Q., & Qureshi, F. Z. (2016). A formal algebra implementation for distributed image and video stream processing. Proceedings of the 10th International Conference on Distributed Smart Camera, 84–91.\n\n\nZhu, E., Nargesian, F., Pu, K. Q., & Miller, R. J. (2016). LSH ensemble: Internet-scale domain search. arXiv Preprint arXiv:1603.07410.\n\n\nHelala, M. A., Qureshi, F. Z., & Pu, K. Q. (2015). Automatic parsing of lane and road boundaries in challenging traffic scenes. Journal of Electronic Imaging, 24(5), 053020–053020.\n\n\nDrake, R., & Pu, K. Q. (2014). Using document space for relational search. Proceedings of the 2014 IEEE 15th International Conference on Information Reuse and Integration (IEEE IRI 2014), 841–844.\n\n\nHelala, M. A., Pu, K. Q., & Qureshi, F. Z. (2014). A stream algebra for computer vision pipelines. Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops, 786–793.\n\n\nHelala, M. A., Pu, K. Q., & Qureshi, F. Z. (2014). Towards efficient feedback control in streaming computer vision pipelines. Asian Conference on Computer Vision, 314–329.\n\n\nYu, Z., Liu, Y., Yu, X., & Pu, K. Q. (2014). Scalable distributed processing of k nearest neighbor queries over moving objects. IEEE Transactions on Knowledge and Data Engineering, 27(5), 1383–1396.\n\n\nHassanzadeh, O., Pu, K. Q., Yeganeh, S. H., Miller, R. J., Popa, L., Hernández, M. A., & Ho, H. (2013). Discovering linkage points over web data. Proceedings of the VLDB Endowment, 6(6), 445–456.\n\n\nHedrick, A., & Pu, K. Q. (2012). Authoring relational queries on the mobile devices. Procedia Computer Science, 10, 752–757.\n\n\nHelala, M. A., Pu, K. Q., & Qureshi, F. Z. (2012). Road boundary detection in challenging scenarios. 2012 IEEE Ninth International Conference on Advanced Video and Signal-Based Surveillance, 428–433.\n\n\nMalloy, W. E., & Pu, K. Q. (2012). Systems and computer program products to identify related data in a multidimensional database.\n\n\nPu, K. Q., & Cheung, R. (2011). Tag grid: Supporting multidimensional queries of tagged datasets. In Recent trends in information reuse and integration (pp. 331–342). Springer Vienna Vienna.\n\n\nRachevsky, L., & Pu, K. Q. (2011). Selection of features for surname classification. 2011 IEEE International Conference on Information Reuse & Integration, 15–20.\n\n\nPu, K. Q., & Cheung, R. (2010). Tag grid: Supporting collaborative and fuzzy multidimensional queries of tagged datasets. 2010 IEEE International Conference on Information Reuse & Integration, 364–367.\n\n\nPu, K. Q., Hassanzadeh, O., Drake, R., & Miller, R. J. (2010). Online annotation of text streams with structured entities. Proceedings of the 19th ACM International Conference on Information and Knowledge Management, 29–38.\n\n\nQ Pu, K. (2010). Recent patents on information retrieval using natural language and keyword query. Recent Patents on Computer Science, 3(3), 186–194.\n\n\nBourennani, F., Pu, K. Q., & Zhu, Y. (2009). Unified vectorization of numerical and textual data using self-organizing map. International Journal On Advances in Systems and Measurements, 2.\n\n\nBourennani, F., Pu, K. Q., & Zhu, Y. (2009). Visual integration tool for heterogeneous data type by unified vectorization. 2009 IEEE International Conference on Information Reuse & Integration, 132–137.\n\n\nBourennani, F., Pu, K. Q., & Zhu, Y. (2009). Visualization and integration of databases using self-organizing map. 2009 First International Confernce on Advances in Databases, Knowledge, and Data Applications, 155–160.\n\n\nPu, K. Q. (2009). Analysis of service compatibility. Services and Business Computing Solutions with XML: Applications for Quality, 136.\n\n\nPu, K. Q. (2009). Keyword query cleaning using hidden markov models. Proceedings of the First International Workshop on Keyword Search on Structured Data, 27–32.\n\n\nPu, K. Q., & Yu, X. (2009). Frisk: Keyword query cleaning and processing in action. 2009 IEEE 25th International Conference on Data Engineering, 1531–1534.\n\n\nZhu, Y., Howard, W., & Pu, K. Q. (2009). Spatial inference using networks of RFID receiver: A bayesian approach. GLOBECOM 2009-2009 IEEE Global Telecommunications Conference, 1–6.\n\n\nMalloy, W. E., & Pu, K. Q. (2008). Methods to identify related data in a multidimensional database.\n\n\nPu, K. Q., & Yu, X. (2008). Keyword query cleaning. Proceedings of the VLDB Endowment, 1(1), 909–920.\n\n\nPu, K. Q., & Zhu, Y. (2008). Modeling and synthesis of service composition using tree automata. 2008 IEEE International Conference on Information Reuse and Integration, 46–51.\n\n\nZhu, Y., Li, B., & Pu, K. Q. (2008). Dynamic multicast in overlay networks with linear capacity constraints. IEEE Transactions on Parallel and Distributed Systems, 20(7), 925–939.\n\n\nZhu, Y., & Pu, K. Q. (2008). Adaptive multicast tree construction for elastic data streams. IEEE GLOBECOM 2008-2008 IEEE Global Telecommunications Conference, 1–5.\n\n\nPu, K. Q. (2007). Service description and analysis from a type theoretic approach. 2007 IEEE 23rd International Conference on Data Engineering Workshop, 379–386.\n\n\nPu, K. Q., & Zhu, Y. (2007). Efficient indexing of heterogeneous data streams with automatic performance configurations. 19th International Conference on Scientific and Statistical Database Management (SSDBM 2007), 34–34.\n\n\nPu, K. Q., & Zhu, Y. (2007). Fast archiving and querying of heterogeneous sensor data streams. 2007 Second International Conference on Digital Telecommunications (ICDT’07), 28–28.\n\n\nChandel, A., Koudas, N., Pu, K. Q., & Srivastava, D. (2006). Fast identification of relational constraint violations. 2007 IEEE 23rd International Conference on Data Engineering, 776–785.\n\n\nPu, K., Hristidis, V., & Koudas, N. (2006). Syntactic rule based approach toweb service composition. 22nd International Conference on Data Engineering (ICDE’06), 31–31.\n\n\nPu, Q. K. (2006). On formal methods of multidimensional databases [PhD thesis].\n\n\nPu, K. Q. (2005). Modeling, querying and reasoning about OLAP databases: A functional approach. Proceedings of the 8th ACM International Workshop on Data Warehousing and OLAP, 1–8.\n\n\nPu, K. Q., & Mendelzon, A. O. (2005). Concise descriptions of subsets of structured sets. ACM Transactions on Database Systems (TODS), 30(1), 211–248.\n\n\nPu, K. Q., & Mendelzon, A. O. (2005). Typed functional query languages with equational specifications. Proceedings of the 14th ACM International Conference on Information and Knowledge Management, 233–234.\n\n\nYu, X., Pu, K. Q., & Koudas, N. (2005). Monitoring k-nearest neighbor queries over moving objects. 21st International Conference on Data Engineering (ICDE’05), 631–642.\n\n\nPu, K. Q. (2004). Functional integration of relational, OLAP and XML data. Proceedings of VLDB Workshop on Information Integration on the Web (IIWeb-2004), 97.\n\n\nMendelzon, A. O., & Pu, K. Q. (2003). Concise descriptions of subsets of structured sets. Proceedings of the Twenty-Second ACM SIGMOD-SIGACT-SIGART Symposium on Principles of Database Systems, 123–133.\n\n\nPu, K. (2000). Modeling and control of discrete-event systems with hierarchical abstraction. Ma sc [PhD thesis]. Thesis, Dept. of Electl. & Cmptr. Engrg., Univ. of Toronto.\n\n\nPu, K. Q. (1998). Theory of discrete wavelet transform and an error analysis of the pyramid algorithm [PhD thesis]. Citeseer."
  },
  {
    "objectID": "publications.html#journals",
    "href": "publications.html#journals",
    "title": "Recent Publications",
    "section": "",
    "text": "Limin Ma, Ken Pu, Ying Zhu, Wesley Taylor, “Comparing Large Language Models for Generating Complex Queries”, Journal of Computer and Communications Vol.13 No.2，February 28, 2025. arxiv manuscript: PDF\nNargesian, Fatemeh, Ken Qian Pu, Bahar Ghadiri Bashardoost, Erkang Zhu, and Renee J. Miller. “Data Lake Organization.” IEEE Transactions on Knowledge and Data Engineering (2022). PDF"
  },
  {
    "objectID": "publications.html#conferences-workshops",
    "href": "publications.html#conferences-workshops",
    "title": "Recent Publications",
    "section": "2 Conferences & Workshops",
    "text": "2 Conferences & Workshops\n\nFu, Z., Yang, C., Davoudi, H. and Pu, K., 2024. “Transforming Text-to-SQL Datasets into Closed-Domain NER Benchmark”. Ontario DataBase Day–Program, p.12.\nLimin Ma and Ken Q. Pu. “Accelerating Relational Keyword Queries With Embedded Predictive Neural Networks.” 2024 IEEE 25th International Conference on Information Reuse and Integration for Data Science (IRI). IEEE Computer Society, 2024.\nMekael Wasti, Ken Q. Pu and Ali Neshati. “Voice Interactive User Interfaces Powered by LLMs.” Intelligent Systems Conference (IntelliSys) 2024.\nPu, Ken, and Limin Ma. “Incremental Computation of Information Gain in Temporal Relational Streams.” 2022 IEEE 23rd International Conference on Information Reuse and Integration for Data Science (IRI). IEEE Computer Society, 2022.\nValdron, Michael, and Pu, Ken. “Data Driven Relational Constraint Programming.” 2020 IEEE 21st International Conference on Information Reuse and Integration for Data Science (IRI). IEEE Computer Society, 2020. PDF\n\n\nA complete list can be found on Google Scholar."
  },
  {
    "objectID": "articles/constraint-modeling.html",
    "href": "articles/constraint-modeling.html",
    "title": "Structured Constraint Programming",
    "section": "",
    "text": "Let’s look at ways we can build constraint programs (CP) in a structured way. As a case study, we will model the curriculum requirements of the Computer Science program."
  },
  {
    "objectID": "articles/constraint-modeling.html#introduction",
    "href": "articles/constraint-modeling.html#introduction",
    "title": "Structured Constraint Programming",
    "section": "",
    "text": "Let’s look at ways we can build constraint programs (CP) in a structured way. As a case study, we will model the curriculum requirements of the Computer Science program."
  },
  {
    "objectID": "articles/constraint-modeling.html#data",
    "href": "articles/constraint-modeling.html#data",
    "title": "Structured Constraint Programming",
    "section": "2 Data",
    "text": "2 Data\nLet’s start with data. The environment is modeled as a database. Let’s build a database to model the curriculum.\n\ndata = []\nfor i in range(4):\n    for s in ['Fall', 'Winter']:\n        data.append(f\"Y{i+1} {s}\")\n\nsemesters = Series(data, name='semesters')\nsemesters\n\n0      Y1 Fall\n1    Y1 Winter\n2      Y2 Fall\n3    Y2 Winter\n4      Y3 Fall\n5    Y3 Winter\n6      Y4 Fall\n7    Y4 Winter\nName: semesters, dtype: object\n\n\n\n\nThe semesters of the curriculum.\n\ndata = [\n    'CSCI 1030U', 'CSCI 1060U', 'CSCI 1061U', 'CSCI 1062U', 'CSCI 1063U', \n    'CSCI 2000U', 'CSCI 2010U', 'CSCI 2020U', 'CSCI 2040U', 'CSCI 2050U',\n    'CSCI 2072U', 'CSCI 2110U', 'CSCI 3010U', 'CSCI 3030U', 'CSCI 3055U', \n    'CSCI 3060U', 'CSCI 3070U', 'CSCI 3090U', 'CSCI 3230U', 'CSCI 3240U', \n    'CSCI 3310U', 'CSCI 3540U', 'CSCI 4020U', 'CSCI 4030U', 'CSCI 4040U', \n    'CSCI 4050U', 'CSCI 4052U', 'CSCI 4055U', 'CSCI 4060U', 'CSCI 4080U', \n    'CSCI 4100U', 'CSCI 4110U', 'CSCI 4140U', 'CSCI 4150U', 'CSCI 4160U', \n    'CSCI 4210U', 'CSCI 4220U', 'CSCI 4230U', 'CSCI 4410U', 'CSCI 4420U', \n    'CSCI 4430U', 'CSCI 4610U', 'CSCI 4620U'\n]\n\ncourses = Series(data, name='courses')\ncourses.head()\n\n0    CSCI 1030U\n1    CSCI 1060U\n2    CSCI 1061U\n3    CSCI 1062U\n4    CSCI 1063U\nName: courses, dtype: object\n\n\nData is needed to model prerequisites and areas of senior courses. For now, let’s get back to these relations laters."
  },
  {
    "objectID": "articles/constraint-modeling.html#unknowns",
    "href": "articles/constraint-modeling.html#unknowns",
    "title": "Structured Constraint Programming",
    "section": "3 Unknowns",
    "text": "3 Unknowns\nWe will also call them independent variables. These are the variables that should be solved to derive the desired solution.\n\ndef make_unknowns(model:CpModel)-&gt;DataFrame:\n    data = np.empty((len(courses), len(semesters)), dtype=object)\n    for i,c in enumerate(courses):\n        for (j, s) in enumerate(semesters):\n            data[i,j] = model.new_bool_var(f\"{c}∈{s}?\")\n\n    unknown = pd.DataFrame(data, index=courses, columns=semesters)\n    return unknown\n\n\nmodel = CpModel()\nunknown = make_unknowns(model)\nunknown.head()\n\n\n\n\n\n\n\nsemesters\nY1 Fall\nY1 Winter\nY2 Fall\nY2 Winter\nY3 Fall\nY3 Winter\nY4 Fall\nY4 Winter\n\n\ncourses\n\n\n\n\n\n\n\n\n\n\n\n\nCSCI 1030U\nCSCI 1030U∈Y1 Fall?\nCSCI 1030U∈Y1 Winter?\nCSCI 1030U∈Y2 Fall?\nCSCI 1030U∈Y2 Winter?\nCSCI 1030U∈Y3 Fall?\nCSCI 1030U∈Y3 Winter?\nCSCI 1030U∈Y4 Fall?\nCSCI 1030U∈Y4 Winter?\n\n\nCSCI 1060U\nCSCI 1060U∈Y1 Fall?\nCSCI 1060U∈Y1 Winter?\nCSCI 1060U∈Y2 Fall?\nCSCI 1060U∈Y2 Winter?\nCSCI 1060U∈Y3 Fall?\nCSCI 1060U∈Y3 Winter?\nCSCI 1060U∈Y4 Fall?\nCSCI 1060U∈Y4 Winter?\n\n\nCSCI 1061U\nCSCI 1061U∈Y1 Fall?\nCSCI 1061U∈Y1 Winter?\nCSCI 1061U∈Y2 Fall?\nCSCI 1061U∈Y2 Winter?\nCSCI 1061U∈Y3 Fall?\nCSCI 1061U∈Y3 Winter?\nCSCI 1061U∈Y4 Fall?\nCSCI 1061U∈Y4 Winter?\n\n\nCSCI 1062U\nCSCI 1062U∈Y1 Fall?\nCSCI 1062U∈Y1 Winter?\nCSCI 1062U∈Y2 Fall?\nCSCI 1062U∈Y2 Winter?\nCSCI 1062U∈Y3 Fall?\nCSCI 1062U∈Y3 Winter?\nCSCI 1062U∈Y4 Fall?\nCSCI 1062U∈Y4 Winter?\n\n\nCSCI 1063U\nCSCI 1063U∈Y1 Fall?\nCSCI 1063U∈Y1 Winter?\nCSCI 1063U∈Y2 Fall?\nCSCI 1063U∈Y2 Winter?\nCSCI 1063U∈Y3 Fall?\nCSCI 1063U∈Y3 Winter?\nCSCI 1063U∈Y4 Fall?\nCSCI 1063U∈Y4 Winter?"
  },
  {
    "objectID": "articles/constraint-modeling.html#constraints",
    "href": "articles/constraint-modeling.html#constraints",
    "title": "Structured Constraint Programming",
    "section": "4 Constraints",
    "text": "4 Constraints\nWe can immediate declare some basic constraints.\n\nEach course can only be taken at most once.\nEach semester can have at most 5 courses.\nMust take lots of courses.\n\n\ndef make_taken_atmost_once(model:CpModel, unknown:DataFrame)-&gt;Series:\n    def fn(row:pd.Series):\n        c = sum(row) &lt;= 1\n        model.Add(c)\n        return c\n\n    return unknown.apply(fn, axis=1)\n\n\n\nEach course can only be taken at most once.\n\nmodel = CpModel()\nunknown = make_unknowns(model)\nC1 = make_taken_atmost_once(model, unknown)\nC1.head()\n\ncourses\nCSCI 1030U    (((((((CSCI 1030U∈Y1 Fall? + CSCI 1030U∈Y1 Win...\nCSCI 1060U    (((((((CSCI 1060U∈Y1 Fall? + CSCI 1060U∈Y1 Win...\nCSCI 1061U    (((((((CSCI 1061U∈Y1 Fall? + CSCI 1061U∈Y1 Win...\nCSCI 1062U    (((((((CSCI 1062U∈Y1 Fall? + CSCI 1062U∈Y1 Win...\nCSCI 1063U    (((((((CSCI 1063U∈Y1 Fall? + CSCI 1063U∈Y1 Win...\ndtype: object\n\n\n\ndef make_semester_atmost_five(model:CpModel, unknown:DataFrame)-&gt;Series:\n    def fn(col:pd.Series):\n        c = sum(col) &lt;= 5\n        model.Add(c)\n        return c\n\n    return unknown.apply(fn, axis=0)\n\n\n\nEach semester can only have at most five courses.\n\nmodel = CpModel()\nunknown = make_unknowns(model)\nC1 = make_semester_atmost_five(model, unknown)\nC1.head()\n\nsemesters\nY1 Fall      ((((((((((((((((((((((((((((((((((((((((((CSCI...\nY1 Winter    ((((((((((((((((((((((((((((((((((((((((((CSCI...\nY2 Fall      ((((((((((((((((((((((((((((((((((((((((((CSCI...\nY2 Winter    ((((((((((((((((((((((((((((((((((((((((((CSCI...\nY3 Fall      ((((((((((((((((((((((((((((((((((((((((((CSCI...\ndtype: object\n\n\n\ndef make_min_selection(model:CpModel, unknown:DataFrame, min:int):\n    vars = unknown.values.reshape(-1)\n    c = sum(vars) &gt; min\n    model.Add(c)\n    return c"
  },
  {
    "objectID": "articles/constraint-modeling.html#dependent-variables",
    "href": "articles/constraint-modeling.html#dependent-variables",
    "title": "Structured Constraint Programming",
    "section": "5 Dependent Variables",
    "text": "5 Dependent Variables\nWe will declare a number of dependent variables. These values are derived from data and unkowns (and maybe other dependent variables). Since the values of unknowns are non-deterministic, derived qualities are also variables.\nThey can be general integer variables.\nLet’s create a set of dependent integer variables, taken_in, which indicates the semester that the courses are taken in. The taken_in[c] is from 1 to \\(n\\) if the course [c] is taken. Otherwise taken_in[c] = 0.\n\ndef make_taken_in(model:CpModel, unknown:DataFrame)-&gt;Series:\n    def fn(row:pd.Series)-&gt;cp_model.IntVar:\n        var = model.NewIntVar(0, len(row)+1, 'taken_in')\n        model.add_map_domain(var, row, offset=1)\n        return var\n\n    taken_in = unknown.apply(fn, axis=1)\n    return taken_in\n\n\nmodel = CpModel()\nunknowns = make_unknowns(model)\ntaken_in = make_taken_in(model, unknown)\n\ntaken_in.head()\n\ncourses\nCSCI 1030U    taken_in\nCSCI 1060U    taken_in\nCSCI 1061U    taken_in\nCSCI 1062U    taken_in\nCSCI 1063U    taken_in\ndtype: object\n\n\nLet’s also define the set of dependent variables, taken, which are booleans indicating of the course is taken.\n\ndef make_taken(model:CpModel, unknown:DataFrame)-&gt;Series:\n    def fn(row:pd.Series)-&gt;cp_model.IntVar:\n        var = model.NewBoolVar('taken')\n        model.AddMaxEquality(var, row)\n        return var\n\n    taken = unknown.apply(fn, axis=1)\n    return taken\n\n\nmodel = CpModel()\nunknown = make_unknowns(model)\ntaken = make_taken(model, unknown)\n\ntaken.head()\n\ncourses\nCSCI 1030U    taken\nCSCI 1060U    taken\nCSCI 1061U    taken\nCSCI 1062U    taken\nCSCI 1063U    taken\ndtype: object"
  },
  {
    "objectID": "articles/constraint-modeling.html#solution",
    "href": "articles/constraint-modeling.html#solution",
    "title": "Structured Constraint Programming",
    "section": "6 Solution",
    "text": "6 Solution\nWe can solve the unknowns (hopefully) and the derived variables using a Solver. The solution will be rendered by views.\n\nmodel = CpModel()\nunknown = make_unknowns(model)\n\n#\n# constraints\n#\ntaken_atmost_once = make_taken_atmost_once(model, unknown)\nsemester_atmost_five = make_semester_atmost_five(model, unknown)\n\n#\n# dependent variables\n#\ntaken_in = make_taken_in(model, unknown)\ntaken = make_taken(model, unknown)\nmake_min_selection(model, unknown, min=35)\n\n#\n# solution\n#\nsolver = cp_model.CpSolver()\nstatus = solver.solve(model)\n\nstatus_name = {\n    cp_model.OPTIMAL: 'optimal',\n    cp_model.FEASIBLE: 'feasible',\n    cp_model.INFEASIBLE: 'infeasible',\n    cp_model.MODEL_INVALID: 'invalid',\n    cp_model.UNKNOWN: 'unknown',\n}[status]\n\nstatus_name\n\n'optimal'"
  },
  {
    "objectID": "articles/constraint-modeling.html#viewing-the-solution",
    "href": "articles/constraint-modeling.html#viewing-the-solution",
    "title": "Structured Constraint Programming",
    "section": "7 Viewing the solution",
    "text": "7 Viewing the solution\n\ndef view(solver:CpSolver, df:DataFrame)-&gt;DataFrame:\n    def fn(x):\n        return solver.value(x)\n    return df.map(fn)\n\n\nview(solver, unknown).head()\n\n\n\n\n\n\n\nsemesters\nY1 Fall\nY1 Winter\nY2 Fall\nY2 Winter\nY3 Fall\nY3 Winter\nY4 Fall\nY4 Winter\n\n\ncourses\n\n\n\n\n\n\n\n\n\n\n\n\nCSCI 1030U\n1\n0\n0\n0\n0\n0\n0\n0\n\n\nCSCI 1060U\n0\n0\n0\n0\n0\n0\n0\n0\n\n\nCSCI 1061U\n0\n0\n0\n0\n0\n0\n0\n0\n\n\nCSCI 1062U\n0\n0\n0\n0\n0\n0\n0\n0\n\n\nCSCI 1063U\n1\n0\n0\n0\n0\n0\n0\n0\n\n\n\n\n\n\n\n\nview(solver, taken_in)\n\ncourses\nCSCI 1030U    1\nCSCI 1060U    0\nCSCI 1061U    0\nCSCI 1062U    0\nCSCI 1063U    1\nCSCI 2000U    1\nCSCI 2010U    1\nCSCI 2020U    1\nCSCI 2040U    2\nCSCI 2050U    2\nCSCI 2072U    2\nCSCI 2110U    2\nCSCI 3010U    2\nCSCI 3030U    3\nCSCI 3055U    3\nCSCI 3060U    3\nCSCI 3070U    3\nCSCI 3090U    3\nCSCI 3230U    4\nCSCI 3240U    4\nCSCI 3310U    4\nCSCI 3540U    4\nCSCI 4020U    4\nCSCI 4030U    5\nCSCI 4040U    5\nCSCI 4050U    5\nCSCI 4052U    5\nCSCI 4055U    5\nCSCI 4060U    6\nCSCI 4080U    6\nCSCI 4100U    6\nCSCI 4110U    6\nCSCI 4140U    6\nCSCI 4150U    7\nCSCI 4160U    7\nCSCI 4210U    7\nCSCI 4220U    7\nCSCI 4230U    7\nCSCI 4410U    8\nCSCI 4420U    8\nCSCI 4430U    8\nCSCI 4610U    8\nCSCI 4620U    8\ndtype: int64\n\n\n\nview(solver, taken_in) \\\n.to_frame() \\\n.reset_index() \\\n.rename(columns={0: 'semester'}) \\\n.groupby(by='semester') \\\n.agg({\n    'courses': lambda x: (f\"{len(x)} :\" + \", \".join(x))\n})\n\n\n\n\n\n\n\n\ncourses\n\n\nsemester\n\n\n\n\n\n0\n3 :CSCI 1060U, CSCI 1061U, CSCI 1062U\n\n\n1\n5 :CSCI 1030U, CSCI 1063U, CSCI 2000U, CSCI 20...\n\n\n2\n5 :CSCI 2040U, CSCI 2050U, CSCI 2072U, CSCI 21...\n\n\n3\n5 :CSCI 3030U, CSCI 3055U, CSCI 3060U, CSCI 30...\n\n\n4\n5 :CSCI 3230U, CSCI 3240U, CSCI 3310U, CSCI 35...\n\n\n5\n5 :CSCI 4030U, CSCI 4040U, CSCI 4050U, CSCI 40...\n\n\n6\n5 :CSCI 4060U, CSCI 4080U, CSCI 4100U, CSCI 41...\n\n\n7\n5 :CSCI 4150U, CSCI 4160U, CSCI 4210U, CSCI 42...\n\n\n8\n5 :CSCI 4410U, CSCI 4420U, CSCI 4430U, CSCI 46..."
  },
  {
    "objectID": "projects/2025-ocr-dataset.html",
    "href": "projects/2025-ocr-dataset.html",
    "title": "Document OCR Dataset",
    "section": "",
    "text": "Database & Automated Workflow, 2025 ©"
  },
  {
    "objectID": "projects/2024-cdner-dataset.html",
    "href": "projects/2024-cdner-dataset.html",
    "title": "Closed-domain NER Dataset",
    "section": "",
    "text": "1 Introduction\nNamed Entity Recognition (NER) is a core problem in natural language processing that involves identifying and categorizing entities within a text into predefined types, such as persons, organizations, locations, etc. The challenge with NER lies in its open-world nature, where each entity type is assumed to have an unconstrained domain, meaning there is no reliance on pre-existing domain knowledge for these entities. This makes the task complex, as the model must generalize to entities it has never encountered before, without any specific constraints regarding the entities’ characteristics or context. The fixed number of entity types provides structure to the problem, but the open-world assumption significantly increases the difficulty of accurately identifying and classifying diverse and novel entities as they appear in real-world texts.\nClosed-Domain NER Challenge: In this research, we assume a closed domain scenario, where each entity type is associated with a database that provides all possible values of the entity. This changes the nature of the NER problem, as the model now has access to a comprehensive list of potential entities for each type, allowing it to leverage this additional information for more accurate tagging. The key research challenge lies in designing an NER tagger that effectively incorporates this closed-domain constraint. Unlike open-domain systems that must rely on statistical patterns and contextual cues alone, the closed-domain approach requires the integration of explicit entity databases, which brings its own set of complexities. The research question centers on how to best combine traditional sequence labeling methods with database lookups, ensuring that the model benefits from the completeness of the closed domain without compromising flexibility or performance.\n\n\n2 CD-NER Dataset\nDataset Creation for Closed-Domain NER (CD-NER): To evaluate potential solutions for the closed-domain NER (CD-NER) problem, it is essential to create a dedicated dataset that reflects the characteristics of a closed domain. This dataset should include texts that feature entities drawn from a well-defined set of types, each with an exhaustive list of possible values provided by associated databases. The dataset must be curated to represent the range of variability within the domain, capturing different contexts in which the entities may appear, while ensuring that all entities are drawn from the closed set. Additionally, the dataset should be split into training, validation, and test sets, with careful attention given to ensuring that no unseen entities appear during testing, which aligns with the closed-domain assumption. Such a dataset will serve as a benchmark to evaluate the effectiveness of CD-NER models in leveraging pre-existing entity databases for improved recognition and categorization accuracy.\n\n\n\n\n\nDatabase & Automated Workflow, 2025 ©"
  },
  {
    "objectID": "articles/annotating_closed_domain_ner.html",
    "href": "articles/annotating_closed_domain_ner.html",
    "title": "Approaches and Challenges in Annotating a Closed Domain NER Dataset",
    "section": "",
    "text": "Named Entity Recognition (NER) is a fundamental task in Natural Language Processing (NLP) that involves identifying and classifying entities in text into predefined categories such as person names, organizations, locations, etc.\n\n\n\nClosed Domain Named Entity Recognition (CD-NER) involves extracting entities from text that correspond to elements of a structured database, such as table names, column names, or partial tuple values. This domain-specific set can contain billions of entities, making extraction a significant challenge. The primary difficulty lies in accurately identifying entities within this closed set while managing the complexities of database size and specificity. CD-NER requires handling specialized vocabulary, leveraging domain-specific context, and dealing with a large fixed pool of entities.\n\n\n\nIn the field of text-to-SQL translation, benchmark datasets like BIRD and Spider have advanced research and established baselines. However, the lack of high-quality CD-NER benchmark datasets limits progress in this area. This article addresses this gap by converting text-to-SQL benchmarks into CD-NER benchmarks. By leveraging structured features from text-to-SQL datasets, we aim to provide a reliable evaluation resource for closed-domain entity extraction."
  },
  {
    "objectID": "articles/annotating_closed_domain_ner.html#introduction",
    "href": "articles/annotating_closed_domain_ner.html#introduction",
    "title": "Approaches and Challenges in Annotating a Closed Domain NER Dataset",
    "section": "",
    "text": "Named Entity Recognition (NER) is a fundamental task in Natural Language Processing (NLP) that involves identifying and classifying entities in text into predefined categories such as person names, organizations, locations, etc.\n\n\n\nClosed Domain Named Entity Recognition (CD-NER) involves extracting entities from text that correspond to elements of a structured database, such as table names, column names, or partial tuple values. This domain-specific set can contain billions of entities, making extraction a significant challenge. The primary difficulty lies in accurately identifying entities within this closed set while managing the complexities of database size and specificity. CD-NER requires handling specialized vocabulary, leveraging domain-specific context, and dealing with a large fixed pool of entities.\n\n\n\nIn the field of text-to-SQL translation, benchmark datasets like BIRD and Spider have advanced research and established baselines. However, the lack of high-quality CD-NER benchmark datasets limits progress in this area. This article addresses this gap by converting text-to-SQL benchmarks into CD-NER benchmarks. By leveraging structured features from text-to-SQL datasets, we aim to provide a reliable evaluation resource for closed-domain entity extraction."
  },
  {
    "objectID": "articles/annotating_closed_domain_ner.html#bird-dataset",
    "href": "articles/annotating_closed_domain_ner.html#bird-dataset",
    "title": "Approaches and Challenges in Annotating a Closed Domain NER Dataset",
    "section": "2 BIRD Dataset",
    "text": "2 BIRD Dataset\nWe’ll be working with the BIRD dataset, which contains natural language questions paired with SQL queries.\n\nimport sys\nfrom pathlib import Path\n\n# Relative project root path\nproject_root = Path(\"../..\")\nsrc_path = project_root / \"5-API\" / \"src\"\ndataset_path = project_root / \"data\" / \"BIRD\"\n\n# Add src directory to Python path\nsys.path.append(str(src_path.resolve()))\n\n\nfrom cdner.datasets import BirdDataset\nfrom cdner.annotators.pglast_annotator import PglastAnnotator\n\n# Initialize the dataset\ndataset = BirdDataset(root=dataset_path, train=True).load()\nexamples_list = list(dataset.examples) \nprint(f\"Number of samples in the dataset: {len(examples_list)}\")\n\nNumber of samples in the dataset: 9428\n\n\n\nfrom pprint import pprint\n# Display the first sample\npprint(examples_list[0].model_dump())\n\n{'db_id': 'movie_platform',\n 'id': 'bird:train.json:0',\n 'query': 'SELECT movie_title FROM movies WHERE movie_release_year = 1945 '\n          'ORDER BY movie_popularity DESC LIMIT 1',\n 'question': 'Name movie titles released in year 1945. Sort the listing by the '\n             'descending order of movie popularity.'}"
  },
  {
    "objectID": "articles/annotating_closed_domain_ner.html#building-cd-ner-benchmarks",
    "href": "articles/annotating_closed_domain_ner.html#building-cd-ner-benchmarks",
    "title": "Approaches and Challenges in Annotating a Closed Domain NER Dataset",
    "section": "3 Building CD-NER Benchmarks",
    "text": "3 Building CD-NER Benchmarks\nTo transform BIRD to CDNER, we map sentence (question text) to lexemes (SQL query entities).\nThis is broken down into the following steps:\n\n3.1 Extracting Lexemes\nWe begin by parsing the SQL queries using pglast, a Python library that parses PostgreSQL SQL statements into an Abstract Syntax Tree (AST). This AST representation allows us to navigate the structure of the SQL queries and extract:\n\nTables: Identified by navigating RangeVar nodes in the AST.\nColumns: Extracted from ColumnRef nodes.\nValues: Retrieved from A_Const nodes representing constants in the query.\n\nThis provides a candidate list that needs to be matched with the question text. We call the extracted entities lexemes.\n\n\n3.2 Matching Lexemes\nOnce we have the list of lexemes, the next step is to match them with substrings in the corresponding natural language question or sentence. Direct string matching is often insufficient due to variations in phrasing, synonyms, or differences in tokenization. To address this, we use a convolutional search with fuzzy string matching:\n\nTokenization: The question text is tokenized, preserving the position of each token for accurate mapping.\nConvolutional Search: We slide a window over the tokens to consider all possible substrings of varying lengths.\nFuzzy Matching: For each substring, we compute a similarity score with the entity using metrics like the token sort ratio from the thefuzz library.\n\n\n\n3.3 Annotating the sentence\nWe annotate each sentence with: - Start and End Positions: Indicating the exact location of the entity in the question. - Label Type: Denoting whether the entity is a table, column, or value. - Lexeme: The original entity extracted from the SQL query. - Similarity Score: Reflecting the confidence of the match.\n\n\n3.4 Applying the BIO Tagging\nFinally, we convert the annotated entities into a BIO tagging format:\n\nB-Label: Marks the beginning of an entity.\nI-Label: Marks tokens inside an entity.\nO: Marks tokens outside any entity."
  },
  {
    "objectID": "articles/annotating_closed_domain_ner.html#step-by-step-example",
    "href": "articles/annotating_closed_domain_ner.html#step-by-step-example",
    "title": "Approaches and Challenges in Annotating a Closed Domain NER Dataset",
    "section": "4 Step-by-Step Example",
    "text": "4 Step-by-Step Example\n\n4.0.1 Extracting Lexemes\nUsing pglast, we parse the SQL query and extract the following lexemes:\n\nannotator = PglastAnnotator()\n\nannotated_example = annotator.annotate(examples_list[0])\npprint(annotated_example.model_dump())\n\n{'entities': [{'end': 34,\n               'label_type': 'column',\n               'lexeme': 'movie_release_year',\n               'schema_element': None,\n               'similarity': 0.77,\n               'start': 5,\n               'substring': 'movie titles released in year'},\n              {'end': 101,\n               'label_type': 'column',\n               'lexeme': 'movie_popularity',\n               'schema_element': None,\n               'similarity': 1.0,\n               'start': 85,\n               'substring': 'movie popularity'},\n              {'end': 17,\n               'label_type': 'column',\n               'lexeme': 'movie_title',\n               'schema_element': None,\n               'similarity': 0.96,\n               'start': 5,\n               'substring': 'movie titles'},\n              {'end': 10,\n               'label_type': 'table',\n               'lexeme': 'movies',\n               'schema_element': None,\n               'similarity': 0.91,\n               'start': 5,\n               'substring': 'movie'},\n              {'end': 39,\n               'label_type': 'value',\n               'lexeme': '1945',\n               'schema_element': None,\n               'similarity': 1.0,\n               'start': 35,\n               'substring': '1945'}],\n 'id': 'bird:train.json:0',\n 'question': 'Name movie titles released in year 1945. Sort the listing by the '\n             'descending order of movie popularity.'}\n\n\n\n\n4.0.2 Matching Lexemes\nWe use convolutional search with fuzzy matching to align lexemes with segments of the sentence (question text). The matching process identifies the most similar substring within a sliding window across the sentence, based on a similarity threshold:\n\nsentence = \"Name movie titles released in year 1945. Sort the listing by the descending order of movie popularity.\"\nlexemes = [\n    ('column', 'movie_release_year'),\n    # ('column', 'movie_popularity'),\n    # ('column', 'movie_title'),\n    # ('table', 'movies'),\n    # ('value', '1945')\n]\nprint(\"Sentence =\",sentence)\nprint(\"lexemes =\", lexemes)\n# Set a similarity threshold\nthreshold = 0.8\n\n# Perform matching\nprint(\"Starting the matching process:\")\nentities = conv_match_substring(sentence, lexemes, threshold=threshold)\n\n# Display the matched entities\nprint(\"\\nMatched entities:\")\nfor entity in entities:\n    print(f\"Entity Type: {entity.label_type}\")\n    print(f\"Matched Text: '{sentence[entity.start:entity.end]}'\")\n    print(f\"Lexeme: {entity.lexeme}\")\n    print(f\"Similarity: {entity.similarity}\\n\")\n\nSentence = Name movie titles released in year 1945. Sort the listing by the descending order of movie popularity.\nlexemes = [('column', 'movie_release_year')]\nStarting the matching process:\n\nMatching lexeme 'movie_release_year' of type 'column'\n\nSearching for best match for phrase 'movie_release_year' in sentence.\nWindow 'Name movie titles released in' (Tokens 0-5): Similarity = 0.64\nWindow 'movie titles released in year' (Tokens 1-6): Similarity = 0.77\nWindow 'titles released in year 1945' (Tokens 2-7): Similarity = 0.61\nWindow 'released in year 1945. Sort' (Tokens 3-8): Similarity = 0.64\nWindow 'in year 1945. Sort the' (Tokens 4-9): Similarity = 0.46\nWindow 'year 1945. Sort the listing' (Tokens 5-10): Similarity = 0.41\nWindow '1945. Sort the listing by' (Tokens 6-11): Similarity = 0.24\nWindow 'Sort the listing by the' (Tokens 7-12): Similarity = 0.29\nWindow 'the listing by the descending' (Tokens 8-13): Similarity = 0.3\nWindow 'listing by the descending order' (Tokens 9-14): Similarity = 0.29\nWindow 'by the descending order of' (Tokens 10-15): Similarity = 0.32\nWindow 'the descending order of movie' (Tokens 11-16): Similarity = 0.43\nWindow 'descending order of movie popularity' (Tokens 12-17): Similarity = 0.41\nWindow size 5: Best match 'movie titles released in year' with similarity 0.77\nWindow 'Name movie titles released' (Tokens 0-4): Similarity = 0.68\nWindow 'movie titles released in' (Tokens 1-5): Similarity = 0.71\nWindow 'titles released in year' (Tokens 2-6): Similarity = 0.68\nWindow 'released in year 1945' (Tokens 3-7): Similarity = 0.72\nWindow 'in year 1945. Sort' (Tokens 4-8): Similarity = 0.46\nWindow 'year 1945. Sort the' (Tokens 5-9): Similarity = 0.44\nWindow '1945. Sort the listing' (Tokens 6-10): Similarity = 0.26\nWindow 'Sort the listing by' (Tokens 7-11): Similarity = 0.27\nWindow 'the listing by the' (Tokens 8-12): Similarity = 0.33\nWindow 'listing by the descending' (Tokens 9-13): Similarity = 0.28\nWindow 'by the descending order' (Tokens 10-14): Similarity = 0.34\nWindow 'the descending order of' (Tokens 11-15): Similarity = 0.29\nWindow 'descending order of movie' (Tokens 12-16): Similarity = 0.42\nWindow 'order of movie popularity' (Tokens 13-17): Similarity = 0.51\nWindow size 4: Best match 'released in year 1945' with similarity 0.72\nWindow 'Name movie titles' (Tokens 0-3): Similarity = 0.57\nWindow 'movie titles released' (Tokens 1-4): Similarity = 0.77\nWindow 'titles released in' (Tokens 2-5): Similarity = 0.61\nWindow 'released in year' (Tokens 3-6): Similarity = 0.82\nWindow 'in year 1945' (Tokens 4-7): Similarity = 0.4\nWindow 'year 1945. Sort' (Tokens 5-8): Similarity = 0.44\nWindow '1945. Sort the' (Tokens 6-9): Similarity = 0.26\nWindow 'Sort the listing' (Tokens 7-10): Similarity = 0.29\nWindow 'the listing by' (Tokens 8-11): Similarity = 0.31\nWindow 'listing by the' (Tokens 9-12): Similarity = 0.31\nWindow 'by the descending' (Tokens 10-13): Similarity = 0.34\nWindow 'the descending order' (Tokens 11-14): Similarity = 0.32\nWindow 'descending order of' (Tokens 12-15): Similarity = 0.32\nWindow 'order of movie' (Tokens 13-16): Similarity = 0.56\nWindow 'of movie popularity' (Tokens 14-17): Similarity = 0.49\nWindow size 3: Best match 'released in year' with similarity 0.82\nWindow 'Name movie' (Tokens 0-2): Similarity = 0.57\nWindow 'movie titles' (Tokens 1-3): Similarity = 0.6\nWindow 'titles released' (Tokens 2-4): Similarity = 0.55\nWindow 'released in' (Tokens 3-5): Similarity = 0.62\nWindow 'in year' (Tokens 4-6): Similarity = 0.48\nWindow 'year 1945' (Tokens 5-7): Similarity = 0.37\nWindow '1945. Sort' (Tokens 6-8): Similarity = 0.22\nWindow 'Sort the' (Tokens 7-9): Similarity = 0.31\nWindow 'the listing' (Tokens 8-10): Similarity = 0.28\nWindow 'listing by' (Tokens 9-11): Similarity = 0.21\nWindow 'by the' (Tokens 10-12): Similarity = 0.17\nWindow 'the descending' (Tokens 11-13): Similarity = 0.31\nWindow 'descending order' (Tokens 12-14): Similarity = 0.35\nWindow 'order of' (Tokens 13-15): Similarity = 0.38\nWindow 'of movie' (Tokens 14-16): Similarity = 0.46\nWindow 'movie popularity' (Tokens 15-17): Similarity = 0.53\nWindow size 2: Best match 'released in' with similarity 0.62\nWindow 'Name' (Tokens 0-1): Similarity = 0.18\nWindow 'movie' (Tokens 1-2): Similarity = 0.43\nWindow 'titles' (Tokens 2-3): Similarity = 0.33\nWindow 'released' (Tokens 3-4): Similarity = 0.54\nWindow 'in' (Tokens 4-5): Similarity = 0.1\nWindow 'year' (Tokens 5-6): Similarity = 0.36\nWindow '1945' (Tokens 6-7): Similarity = 0.0\nWindow 'Sort' (Tokens 7-8): Similarity = 0.18\nWindow 'the' (Tokens 8-9): Similarity = 0.1\nWindow 'listing' (Tokens 9-10): Similarity = 0.16\nWindow 'by' (Tokens 10-11): Similarity = 0.1\nWindow 'the' (Tokens 11-12): Similarity = 0.1\nWindow 'descending' (Tokens 12-13): Similarity = 0.21\nWindow 'order' (Tokens 13-14): Similarity = 0.35\nWindow 'of' (Tokens 14-15): Similarity = 0.1\nWindow 'movie' (Tokens 15-16): Similarity = 0.43\nWindow 'popularity' (Tokens 16-17): Similarity = 0.29\nWindow size 1: Best match 'released' with similarity 0.54\n\nBest overall match: 'released in year' with similarity 0.82\nMatched 'released in year' in sentence with similarity 0.82\n\nMatched entities:\nEntity Type: column\nMatched Text: 'released in year'\nLexeme: movie_release_year\nSimilarity: 0.82"
  },
  {
    "objectID": "articles/annotating_closed_domain_ner.html#challenges",
    "href": "articles/annotating_closed_domain_ner.html#challenges",
    "title": "Approaches and Challenges in Annotating a Closed Domain NER Dataset",
    "section": "5 Challenges",
    "text": "5 Challenges\n\nAlignment Issues:\n\nNatural language questions often use varied phrasing that doesn’t directly match the lexemes (e.g., table names, column names) in the database schema.\n\nOverlapping Entities:\n\nWhen multiple entities are mentioned closely together in a question, their textual representations can overlap.\n\n\nWe can approach the challenge in the following ways:\n\nAlignment\n\nContinous Annotation: Only continuous (adjacent) substrings in the sentence can be annotated as entities. This means that the words corresponding to an entity must be next to each other without any interruptions.\nNon-continuous Annotation: Allows for the annotation of entities even if the corresponding words are not adjacent in the sentence. This approach is more flexible and can capture entities that are mentioned in a scattered manner throughout the sentence.\n\nOverlap\n\nOverlap Annotation: Annotations are allowed to overlap in the sentence; that is, a word or phrase can be part of multiple entity annotations. This is useful when different entities share common words in the question.\nNon-overlap Annotation: Annotations cannot overlap; each word or phrase can be assigned to at most one entity. This constraint ensures that once a word is part of an entity annotation, it cannot be part of another.\n\n\n\n5.1 Example\nSuppose the following sentence and lexemes:\n\nsentence = \"Name movie titles released in year 1945. Sort the listing by the descending order of movie popularity.\"\nlexemes = [\n    ('column', 'movie_release_year'),\n    ('column', 'movie_popularity'),\n    ('column', 'movie_title'),\n    ('table', 'movies'),\n    ('value', '1945')\n]\n\n\n\n5.2 Continous Overlapping\nDefinition: Only continuous substrings in the sentence can be annotated as entities, and annotations are allowed to overlap (i.e., a word or phrase can be part of multiple annotations).\nSentence: “Name [{movie} titles] [released in year] [1945]. Sort the listing by the descending order of [movie popularity].”\n\n{movie} and [movie released in year] matches to the ‘movie_release_year’ column.\n[movie titles] matches the ‘movie_title’ column.\n[1945] matches the ‘1945’ value.\n[movie popularity] matches the ‘movie_popularity’ column.\n\n\n\n5.3 Continuous Non-Overlapping\nDefinition: Only continuous substrings in the sentence can be annotated as entities, and annotations cannot overlap (i.e., each word or phrase can be part of at most one annotation).\nSentence: “Name [movie titles] [released in year] [1945]. Sort the listing by the descending order of [movie popularity].”\n\n[movie titles] matches the ‘movie_title’ column.\n[released in year] matches the ‘movie_release_year’ column.\n[1945] matches the ‘1945’ value.\n[movie popularity] matches the ‘movie_popularity’ column.\n\n\n\n5.4 Non-Continuous Overlapping\nDefinition: Substrings can be non-continuous (i.e., words corresponding to an entity do not need to be adjacent), and annotations are allowed to overlap.\nSentence: “Name [{movie} titles] [released] in [year] [1945]. Sort the listing by the descending order of [{movie} popularity].”\n\n{movie} matches the ‘movies’ table.\n[movie titles] separately match the ‘movie_title’ columns.\n{movie}, [released] and [year] correspond to the ‘movie_release_year’ columns.\n[1945] matches the ‘1945’ value.\n[movie popularity] correspond to the ‘movie_popularity’ column.\n\n\n\n5.5 Non-Continuous Non-Overlapping\nDefinition: Substrings can be non-continuous, and annotations cannot overlap.\nSentence: “Name [movie] [titles] [released] in [year] [1945]. Sort the listing by the descending order of [movie] [popularity].”\n\n[movie] matches the ‘movies’ table or ‘movie_title’ column.\n[titles] matches the ‘movie_title’ column.\n[released] matches the ‘movie_release_year’ column.\n[year] matches the ‘movie_release_year’ column.\n[1945] matches the ‘1945’ value.\n[movie] [popularity] matches the ‘movie_popularity’ column."
  },
  {
    "objectID": "articles/index.html",
    "href": "articles/index.html",
    "title": "Articles",
    "section": "",
    "text": "Order By\n      Default\n      \n        Title\n      \n      \n        Author\n      \n    \n  \n    \n      \n      \n    \n\n\n\n\n\n\nTitle\n\n\n\nAuthor\n\n\n\n\n\n\n\n\nApproaches and Challenges in Annotating a Closed Domain NER Dataset\n\n\nZikun Fu\n\n\n\n\n\n\nStructured Constraint Programming\n\n\nKen Pu\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "1 Research Statement",
    "section": "",
    "text": "Databases, AI and Workflow Automation"
  },
  {
    "objectID": "index.html#fundamental-ai-research",
    "href": "index.html#fundamental-ai-research",
    "title": "1 Research Statement",
    "section": "1.1 Fundamental AI research",
    "text": "1.1 Fundamental AI research\nWe aim to advance the foundations of data science, machine learning, and agentic AI.\n\nmathematical models of neural network dynamics\nmeta-learning methods for ensemble learning\nintegration of AI with classical computer science"
  },
  {
    "objectID": "index.html#novel-applications-of-ai",
    "href": "index.html#novel-applications-of-ai",
    "title": "1 Research Statement",
    "section": "1.2 Novel applications of AI",
    "text": "1.2 Novel applications of AI\nOur research focuses on discovering and implementing novel applications of AI technology, particularly in workflow automation. We aim to enhance efficiency, reduce costs, and improve accuracy in various business processes."
  },
  {
    "objectID": "index.html#open-source-benchmarks",
    "href": "index.html#open-source-benchmarks",
    "title": "1 Research Statement",
    "section": "1.3 Open-source benchmarks",
    "text": "1.3 Open-source benchmarks\nWe are committed to providing the research community with open source benchmarks to evaluate AI models and technologies. These benchmarks are crucial for ensuring transparency, reproducibility, and progress in the field of AI research."
  },
  {
    "objectID": "index.html#ai-readiness-report",
    "href": "index.html#ai-readiness-report",
    "title": "1 Research Statement",
    "section": "1.4 AI readiness report",
    "text": "1.4 AI readiness report\nWe assess AI readiness across various industry sectors, identifying opportunities and challenges. Our reports offer insights into the practical implementation of AI technologies and their impact on industry operations."
  },
  {
    "objectID": "projects/2025-ppx.html",
    "href": "projects/2025-ppx.html",
    "title": "Document understanding",
    "section": "",
    "text": "Database & Automated Workflow, 2025 ©"
  },
  {
    "objectID": "publications.html#citations-go-here--yu2005monitoring--pu2006syntactic--pu2000modeling--pu2008keyword--zhu2008dynamic--pu2005concise--mendelzon2003concise--malloy2008methods--pu2009keyword--bourennani2009visual--bourennani2009visualization--pu2010online--pu2009frisk--pu2005modeling--pu2007efficient--pu2010tag--zhu2008adaptive--chandel2006fast--zhu2009spatial--pu2006formal--pu2008modeling--bourennani2009unified--pu2007service--rachevsky2011selection--pu2005typed--pu1998theory--q2010recent--pu2007fast--pu2004functional--pu2011tag--malloy2012systems--helala2012road--hedrick2012authoring--hassanzadeh2013discovering--helala2014stream--helala2014towards--yu2014scalable--drake2014using--helala2015automatic--zhu2016lsh--helala2016formal--ferron2016arc--pu2009analysis--hedrick2016hierarchical--hedrick2017modeling--zhu2017interactive--reina2017index--nargesian2018table--miller2018making--beiraimi2018towards--nargesian2022data--nargesian2019data--beirami2019trusted--stoica2019scalable--nargesian2020organizing--helala2020stream--polovina2020move--mior2020semantic--stoica2020nlp--valdron2020data--ouellette2021ronin--pu2022incremental--ma2022neural--nargesian2018data--ma2024evaluating--mekael2024large--wasti2024large--ma2024accelerating--fu2024transforming--ma2025comparing--fu2025database",
    "href": "publications.html#citations-go-here--yu2005monitoring--pu2006syntactic--pu2000modeling--pu2008keyword--zhu2008dynamic--pu2005concise--mendelzon2003concise--malloy2008methods--pu2009keyword--bourennani2009visual--bourennani2009visualization--pu2010online--pu2009frisk--pu2005modeling--pu2007efficient--pu2010tag--zhu2008adaptive--chandel2006fast--zhu2009spatial--pu2006formal--pu2008modeling--bourennani2009unified--pu2007service--rachevsky2011selection--pu2005typed--pu1998theory--q2010recent--pu2007fast--pu2004functional--pu2011tag--malloy2012systems--helala2012road--hedrick2012authoring--hassanzadeh2013discovering--helala2014stream--helala2014towards--yu2014scalable--drake2014using--helala2015automatic--zhu2016lsh--helala2016formal--ferron2016arc--pu2009analysis--hedrick2016hierarchical--hedrick2017modeling--zhu2017interactive--reina2017index--nargesian2018table--miller2018making--beiraimi2018towards--nargesian2022data--nargesian2019data--beirami2019trusted--stoica2019scalable--nargesian2020organizing--helala2020stream--polovina2020move--mior2020semantic--stoica2020nlp--valdron2020data--ouellette2021ronin--pu2022incremental--ma2022neural--nargesian2018data--ma2024evaluating--mekael2024large--wasti2024large--ma2024accelerating--fu2024transforming--ma2025comparing--fu2025database",
    "title": "Publications",
    "section": "1 Citations go here- [@yu2005monitoring]- [@pu2006syntactic]- [@pu2000modeling]- [@pu2008keyword]- [@zhu2008dynamic]- [@pu2005concise]- [@mendelzon2003concise]- [@malloy2008methods]- [@pu2009keyword]- [@bourennani2009visual]- [@bourennani2009visualization]- [@pu2010online]- [@pu2009frisk]- [@pu2005modeling]- [@pu2007efficient]- [@pu2010tag]- [@zhu2008adaptive]- [@chandel2006fast]- [@zhu2009spatial]- [@pu2006formal]- [@pu2008modeling]- [@bourennani2009unified]- [@pu2007service]- [@rachevsky2011selection]- [@pu2005typed]- [@pu1998theory]- [@q2010recent]- [@pu2007fast]- [@pu2004functional]- [@pu2011tag]- [@malloy2012systems]- [@helala2012road]- [@hedrick2012authoring]- [@hassanzadeh2013discovering]- [@helala2014stream]- [@helala2014towards]- [@yu2014scalable]- [@drake2014using]- [@helala2015automatic]- [@zhu2016lsh]- [@helala2016formal]- [@ferron2016arc]- [@pu2009analysis]- [@hedrick2016hierarchical]- [@hedrick2017modeling]- [@zhu2017interactive]- [@reina2017index]- [@nargesian2018table]- [@miller2018making]- [@beiraimi2018towards]- [@nargesian2022data]- [@nargesian2019data]- [@beirami2019trusted]- [@stoica2019scalable]- [@nargesian2020organizing]- [@helala2020stream]- [@polovina2020move]- [@mior2020semantic]- [@stoica2020nlp]- [@valdron2020data]- [@ouellette2021ronin]- [@pu2022incremental]- [@ma2022neural]- [@nargesian2018data]- [@ma2024evaluating]- [@mekael2024large]- [@wasti2024large]- [@ma2024accelerating]- [@fu2024transforming]- [@ma2025comparing]- [@fu2025database]",
    "text": "1 Citations go here- [@yu2005monitoring]- [@pu2006syntactic]- [@pu2000modeling]- [@pu2008keyword]- [@zhu2008dynamic]- [@pu2005concise]- [@mendelzon2003concise]- [@malloy2008methods]- [@pu2009keyword]- [@bourennani2009visual]- [@bourennani2009visualization]- [@pu2010online]- [@pu2009frisk]- [@pu2005modeling]- [@pu2007efficient]- [@pu2010tag]- [@zhu2008adaptive]- [@chandel2006fast]- [@zhu2009spatial]- [@pu2006formal]- [@pu2008modeling]- [@bourennani2009unified]- [@pu2007service]- [@rachevsky2011selection]- [@pu2005typed]- [@pu1998theory]- [@q2010recent]- [@pu2007fast]- [@pu2004functional]- [@pu2011tag]- [@malloy2012systems]- [@helala2012road]- [@hedrick2012authoring]- [@hassanzadeh2013discovering]- [@helala2014stream]- [@helala2014towards]- [@yu2014scalable]- [@drake2014using]- [@helala2015automatic]- [@zhu2016lsh]- [@helala2016formal]- [@ferron2016arc]- [@pu2009analysis]- [@hedrick2016hierarchical]- [@hedrick2017modeling]- [@zhu2017interactive]- [@reina2017index]- [@nargesian2018table]- [@miller2018making]- [@beiraimi2018towards]- [@nargesian2022data]- [@nargesian2019data]- [@beirami2019trusted]- [@stoica2019scalable]- [@nargesian2020organizing]- [@helala2020stream]- [@polovina2020move]- [@mior2020semantic]- [@stoica2020nlp]- [@valdron2020data]- [@ouellette2021ronin]- [@pu2022incremental]- [@ma2022neural]- [@nargesian2018data]- [@ma2024evaluating]- [@mekael2024large]- [@wasti2024large]- [@ma2024accelerating]- [@fu2024transforming]- [@ma2025comparing]- [@fu2025database]"
  },
  {
    "objectID": "publications.html#references",
    "href": "publications.html#references",
    "title": "Publications",
    "section": "1 References",
    "text": "1 References"
  }
]